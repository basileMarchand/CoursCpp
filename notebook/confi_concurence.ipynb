{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Programmation concurrente en C++"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans le cours **Programmes Coopérants** vous avez les bases de la programmation concurentes en Python à l'aide de la création de process ou de thread. Vous avez également vu comment il est possible de faire du calcul parallèle et donc exploiter les architecture des super calculateurs moderne via le protocol MPI. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans ce cours nous allons reprendre une partie de ce qui a été abordé mais en nous focalisant sur l'utilisation du C++. Plus précisément nous allons voir comment faire de la programmation concurrente en C++ via deux aspects : (i) l'utilisation du multithread ; (ii) l'utilisation de modèle de programmation asynchrone. \n",
    "\n",
    "Alors si des puristes lisent ce notebook, ils pourraient être tenté de dire que le multi-thread ce n'est pas forcément du concurrent mais du parallèles et que de l'asynchrone ce n'est pas du concurrent... C'est une question de point de vue. Plus précisément ce que l'on va voir aujourd'hui c'est comment faire un programme qui va devoir effectuer un grand nombre de tâches (une tâches étant une série d'instruction) et les effectuer le plus rapidement possible en tirant au maximum parti des ressources matériel à disposition. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rappel sur les *lambda* fonctions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour commencer faisons juste un petit rappel sur les fonctions anonymes ou *lambda* fonctions. En effet lorsque l'on fait de la programmation concurrentes en C++ les fonctions anonymes s'avèrent être extrèmement pratique pour se simplifier la vie. Nous allons donc rapidement faire un tour d'horizon des leurs définitions et utilisations. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La syntaxe générale des fonctions anonymes est la suivante : \n",
    "\n",
    "```c++\n",
    "[capture]( params ) -> ret { body }\n",
    "```\n",
    "\n",
    "* `params` représente la liste des paramètres d'entrée de votre fonction, donc une suite de paramètres nommés et typés, comme dans une fonction classique\n",
    "* `ret` est le type de retour de votre fonction anonyme, vous pouvez ne pas le préciser il est alors automatiquement déduit si le mot clé `return est présent dans `body` sinon il est considéré comme `void`\n",
    "* `body` le corp de votre fonction\n",
    "* `capture` une liste de variables existantes dans le scope de déclaration de la fonction anonyme est devant être transmises au scope interne à la fonction.\n",
    "\n",
    "Vous pouvez si vous le souhaitez stocker votre fonction anonyme dans une variables pour l'utiliser ensuite de la manière suivante :\n",
    "\n",
    "```c++\n",
    "auto f = [capture](params) -> ret { body }\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Regardons tout de suite un exemple: \n",
    "\n",
    "```c++\n",
    "#include <iostream>\n",
    "\n",
    "int main{\n",
    "\n",
    "    auto f = [](const std::string& msg){\n",
    "        std::cout << msg << \"\\n\";\n",
    "    }\n",
    "\n",
    "    f(\"coucou\")\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Pour expliquer cette histoire de `capture` regardons l'exemple suivant : \n",
    "\n",
    "```c++\n",
    "\n",
    "double a=2.1;\n",
    "auto f = [](){ std::cout << \"a = \" << a << \"\\n\" ; };\n",
    "// Compilation Error 'a' is not captured \n",
    "```\n",
    "\n",
    "En effet ce code ne compile pas car `a` est bien définit mais n'est pas accessible depuis l'intérieur de la lambda fonction. Une solution me direz vous est alors de passer a comme arguments d'entrée de la fonction. Oui c'est vrai. Mais on peut également utiliser le `capture` de la lambda fonction pour capturer `a` dans le scope de la fonction. Cela donne : \n",
    "\n",
    "```c++\n",
    "\n",
    "double a=2.1;\n",
    "auto f = [a](){ std::cout << \"a = \" << a << \"\\n\" ; };\n",
    "```\n",
    "\n",
    "En revanche avec cette approche, la variable `a` est en lecture seule au sein de la fonction anonyme. C'est-à-dire que l'on ne peut pas modifier la variable `a` dans la fonction. Si vous souhaitez pouvoir modifier la valeu de `a` il faut la capturer par référence. \n",
    "\n",
    "```c++\n",
    "\n",
    "double a=2.1;\n",
    "auto f = [&a](){ \n",
    "    std::cout << \"a = \" << a << \"\\n\" ; \n",
    "    a = 1024.0;\n",
    "    };\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Remarque* il existe une syntaxe particulière au niveau du capture permettant de capturer toutes les variables présentent dans le scope de définition de la fonction pour les injecter dans le scope interne de la fonction. Il s'agit de :\n",
    "\n",
    "* `[=]` qui capture toutes les variables par copie\n",
    "* `[&]` qui capture toutes les variables par références, permettant ainsi de les modifiers au sein de la fonction. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Remarque 2* bien évidemment ces notations qui ont l'air très pratiques d'utilisation sont plutôt à éviter car je suis sur que vous en conviendrez ce n'est pas très propre comme approche. Ca manque de classe !"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programmation multi-thread"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Après ce bref rappel au sujet des fonctions anonymes nous allons pouvoir entrer dans le vif du sujet. Nous allons donc commencer par voir comment faire de la programmation multi-thread en c++. \n",
    "\n",
    "Pour rappel le modèle de programmation multi-thread a pour principe d'exploiter au maximum l'architecture multi-coeurs des processeurs récent. Pour cela le programme principal va créer des threads qui vont s'exécuter de manière concurrente sur les différents coeurs de votre processeurs. Pour ceux qui auraient oublié un thread, également appelé processus léger, est un ensemble d'instuction machine regroupé au sein d'une pile d'exécution partageant sa mémoire avec le processus l'ayant créé. Formulé autrement des threads sont des blocs d'instruction c++ partageant entre eux la même mémoire. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depuis la norme 2011 du c++, c++11, l'utilisation des threads est fortement simplifiée. Il vous suffit d'inclure le header file correspondant \n",
    "\n",
    "```c++\n",
    "#include <thread>\n",
    "```\n",
    "\n",
    "L'élément de base est la classe `std::thread` qui va nous permettre de créer un thread pour une fonction donnée.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considérons tout de suite l'exemple suivant d'une fonction `main` créant un `thread` chargé d'afficher dix fois le même message.\n",
    "\n",
    "```c++\n",
    "#include <thread>\n",
    "#include <iostream>\n",
    "\n",
    "int main(){\n",
    "    std::thread t = std::thread([]()->void {\n",
    "        for( int i=0; i<10; i++ ){\n",
    "            std::cout << \"Hello World from thread\" << std::endl;\n",
    "        }\n",
    "    });\n",
    "\n",
    "    std::cout << \"Hello World from the main function \" << std::endl;\n",
    "\n",
    "    t.join();\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "```\n",
    "\n",
    "\n",
    "On constate alors à l'exécution que le thread et le programme principale vive chacun leur vie. Bien evidémment il est possible de créer autant de thread qu'on le souhaite dans un programme.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```c++\n",
    "#include <thread>\n",
    "#include <iostream>\n",
    "\n",
    "int main(){\n",
    "    const int n_threads {10};\n",
    "\n",
    "    std::vector<std::thread> _threads;\n",
    "\n",
    "    for( int i=0; i<n_threads; i++){\n",
    "        _threads.push_back(std::thread([](const int& tid)->void {\n",
    "                            for( int i=0; i<10; i++ ){\n",
    "                                 std::cout << \"Hello World from thread \"<< tid << std::endl;\n",
    "                            }\n",
    "            }, i)\n",
    "        );\n",
    "    }\n",
    "\n",
    "    std::cout << \"Hello World from the main function \" << std::endl;\n",
    "\n",
    "    for(std::thread& t: _threads){\n",
    "        t.join();\n",
    "    }\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En exécutant ce code plusieurs fois sur votre ordinateur portable vous allez alors voir apparaître quelque chose de potentiellement étrange... De temps quelques lignes de la sortie sont entremélées entre elles. Par exemple \n",
    "\n",
    "```\n",
    "Hello World from thread 5Hello World from thread 7\n",
    "Hello World from thread Hello World from thread \n",
    "Hello World from thread Hello World from thread 5\n",
    "8\n",
    "Hello World from thread 8\n",
    "7\n",
    "```\n",
    "\n",
    "Bizarre non ? Un avis sur la question ? C'est un effet de ce que l'on appel un `race condition` ! Le principe est simple, nous avons deux threads qui accède simultanément à la même variables partagée et la modifie. C'est le risque lorsque l'on fait du multithread. Pour prévenir cela il est nécessaire de mettre en place des mécanismes de verrouillage. \n",
    "￼\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilisations des mutex"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un mutex, *Mutual Exclusion*, est un objet utilisé en programmation concurrente pour éviter que différents threads n'accèdent simulténament à des ressources partagées. Pour utiliser un `mutex` en c++ il vous suffit d'inclure le header file correspondant\n",
    "\n",
    "```c++\n",
    "#include <mutex>\n",
    "```\n",
    "\n",
    "L'objet de base est `std::mutex`, oui ça manque d'originalité tout ça je sais. Cet objet est extrèmement simple car il ne possède que deux méthodes `lock()` et `unlock()`. Comme le nom le laisse imaginer ces deux méthodes ont respectivement pour but de bloquer  et débloquer les threads. \n",
    "\n",
    "Reprenons tout de suite l'exemple précédent. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```c++\n",
    "#include <vector>\n",
    "#include <thread>\n",
    "#include <iostream>\n",
    "#include <mutex>\n",
    "\n",
    "std::mutex mtx;\n",
    "\n",
    "int main(){\n",
    "  const int n_threads {10};\n",
    "\n",
    "  std::vector<std::thread> _threads;\n",
    "\n",
    "  for( int i=0; i<n_threads; i++){\n",
    "    _threads.push_back(std::thread([](const int& tid)->void {\n",
    "          for( int i=0; i<10; i++ ){\n",
    "            mtx.lock();\n",
    "            std::cout << \"Hello World from thread \"<< tid << std::endl;\n",
    "            mtx.unlock();\n",
    "          }\n",
    "\t}, i)\n",
    "      );\n",
    "  }\n",
    "\n",
    "  std::cout << \"Hello World from the main function \" << std::endl;\n",
    "\n",
    "  for(std::thread& t: _threads){\n",
    "    t.join();\n",
    "  }\n",
    "\n",
    "  return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Afin d'assurer qu'il n'y a pas d'accès simultanés à la sorte standard, via le `std::cout`, on encadre donc la ligne `std::cout` par un appel à la méthode `lock()` entrainant ainsi l'arrêt des autres threads et ensuite un appel à `unlock` pour débloquer les threads. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attention** l'utilisation d'un mutex permet en effet de résoudre les problèmes d'accès concurrents aux ressources partagées. En revanche cela a un prix, il s'agit de la performance. En effet le fait de bloquer/débloquer des threads prends un temps minime certe mais non nul. Donc si on répête cette opération de nombreuses foix cela va fortement dégrader les performances. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Attention** il faut faire très attention lorsque vous utilisez un mutex au fait qu'un `lock` doit toujours être associé à un `unlock` sinon votre programme va se bloquer définitivement. Cela peut s'avérer parfois délicat notamment quand on doit en plus gérer les exceptions. Pour faciliter cela il existe dans la librairie standard, l'objet `std::unique_lock<Mutex>`. Ce dernier permet de faire un `lock` et surtout de déverouiller le mutex à la sortie du context, i.e. sortie de fonction par exemple. Par exemple voici ci-dessous un usage où l'on ne fait pas le `unlock` manuellement :\n",
    "\n",
    "```c++\n",
    "#include <iostream>       // std::cout\n",
    "#include <thread>         // std::thread\n",
    "#include <mutex>          // std::mutex, std::unique_lock\n",
    "\n",
    "std::mutex mtx;           // mutex for critical section\n",
    "\n",
    "void print_block (int n, char c) {\n",
    "  std::unique_lock<std::mutex> lck (mtx);\n",
    "  for (int i=0; i<n; ++i) { std::cout << c; }\n",
    "  std::cout << '\\n';\n",
    "}\n",
    "\n",
    "int main ()\n",
    "{\n",
    "  std::thread th1 (print_block,50,'*');\n",
    "  std::thread th2 (print_block,50,'$');\n",
    "\n",
    "  th1.join();\n",
    "  th2.join();\n",
    "\n",
    "  return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour illustrer cela considérons par exemple le calcul de $\\pi$. Une manière possible pour calculer $\\pi$ est d'évaluer numériquement l'intégrale suivante :\n",
    "\n",
    "$$ \\pi = \\int_{0}^{1} \\frac{4}{1+x^2} $$\n",
    "\n",
    "Le calcul séquentiel classique peut se faire de la manière suivante : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```c++\n",
    "#include <iostream> \n",
    "\n",
    "int main(){\n",
    "\n",
    "    int nb_point = 100000000;\n",
    "    double l=1./nb_point;\n",
    "\n",
    "    double pi=0;\n",
    "    for( int i=0; i<nb_point; i++){\n",
    "        double x=l*(i+0.5);\n",
    "        pi += l*( 4. / (1. + x*x ) );\n",
    "    }\n",
    "\n",
    "    std::cout << \"PI = \" << pi << std::endl;\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "```\n",
    "\n",
    "Si vous lancez alors ce code et mesurez le temps d'exécution vous obtenez le résultat suivant : \n",
    "\n",
    "```bash \n",
    "0.84user 0.00system 0:00.85elapsed 98%CPU\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si l'on fait alors une version multi-thread naïve, c'est à dire avec plein de `lock`/`unlock`. Cela pourrait donner le code suivant : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```c++\n",
    "std::mutex mtx;\n",
    "\n",
    "void pi_thread_worker(const uint& nbpoint, const uint tid, const uint nbthread, double& pi){\n",
    "    double s = 0.;\n",
    "    double l = 1./nbpoint;\n",
    "    int start = tid*(nbpoint/nbthread);\n",
    "    int stop = (tid+1)*(nbpoint/nbthread);\n",
    "    if( tid == nbthread-1){\n",
    "        stop += nbpoint%nbthread;\n",
    "    }\n",
    "\n",
    "    double x;\n",
    "    for( int i=start; i<stop; i++){\n",
    "        x = l * ( i + 0.5 );\n",
    "        mtx.lock();\n",
    "        pi += l * ( 4. / (1 + x*x ) );\n",
    "        mtx.unlock();   \n",
    "    }\n",
    "}\n",
    "\n",
    "int main(){\n",
    "    if( argc == 1 ){\n",
    "        std::cerr << \"Specify the number of thread\" << std::endl;\n",
    "        return 1;\n",
    "    }\n",
    "\n",
    "    int nb_point = 100000000;\n",
    "    int nb_thread = atoi(argv[1]);\n",
    "\n",
    "    double pi=0;\n",
    "    std::vector<std::thread> threads;\n",
    "    for( int i=0; i<nb_thread; i++){\n",
    "        threads.push_back( std::thread( pi_thread_worker, nb_point, i, nb_thread, std::ref(pi) ) );\n",
    "    }\n",
    "\n",
    "    for( int i=0; i<nb_thread; i++){\n",
    "        threads[i].join();\n",
    "    }\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si on lance alors ce code avec deux threads on obtient le résultat suivant : \n",
    "\n",
    "```bash \n",
    "11.56user 11.78system 0:11.84elapsed 197%CPU\n",
    "```\n",
    "\n",
    "On est donc plus de 10 fois plus lent que la version séquentiel !!!!! C'est normal en même temps, le code précédent c'est du grand n'importe quoi !!! En effet plutôt que de faire les `lock`/`unlock` dans la boucle il est préférable de créer une variable temporaire dans le thread. \n",
    "\n",
    "```c++\n",
    "void pi_thread_worker(const uint& nbpoint, const uint tid, const uint nbthread, double& pi){\n",
    "    double s = 0.;\n",
    "    double l = 1./nbpoint;\n",
    "    int start = tid*(nbpoint/nbthread);\n",
    "    int stop = (tid+1)*(nbpoint/nbthread);\n",
    "    if( tid == nbthread-1){\n",
    "        stop += nbpoint%nbthread;\n",
    "    }\n",
    "\n",
    "    double x;\n",
    "    double tmp=0;\n",
    "    for( int i=start; i<stop; i++){\n",
    "        x = l * ( i + 0.5 );\n",
    "        tmp += l * ( 4. / (1 + x*x ) );\n",
    "    }\n",
    "    mtx.lock();\n",
    "    pi += tmp;\n",
    "    mtx.unlock():\n",
    "}\n",
    "```\n",
    "\n",
    "Si on relance alors ce code, avec cette légère modification, toujours avec deux threads on obtient le résultat suivant : \n",
    "```bash \n",
    "0.95user 0.00system 0:00.49elapsed 195%CPU\n",
    "```\n",
    "\n",
    "On obtient donc dans ce cas un temps d'exécution diviser d'un facteur presque 2 par rapport à la version séquentiel. Comme quoi le langage ne fait pas tout le rigolo derrière le clavier a une part de responsabilité ... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Exercice** refaite le calcul de $\\pi$ en multi-thread sans aucun mutex ! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Programmation asynchrone"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nous allons à présent voir une autre approche de programmation concurrente la programmation asynchrone. Le principe est de permettre l'exécution de tâches nécessitants un temps non négligeable en parallèle du fil d'exécution principale. Le modèle asynchrone a commencé a apparaître avec l'émergence des services web, base de données en lignes, ... Le principe est de permettre l'exécution en \"tâche de fond\" des fonctions consommatrice en temps mais pas en ressources, par exemple des requêtes sur une base de données, l'écriture ou la lecture de fichiers, ...  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Depuis la norme c++11 le C++ offre tout ce qu'il faut pour faire de la programmation asynchrone facilement. Tout ce dont vous avez besoin se trouve dans le header `future`\n",
    "\n",
    "```c++\n",
    "#include <future>\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'élément de base est la fonction `std::async` qui prend en argument : \n",
    "\n",
    "* Une politique d'exécution qui permet de controler le comportement asynchrone \n",
    "    * `std::launch::async` exécute la fonction de manière asynchrone dans un thread séparé\n",
    "    * `std::launch::deferred` exécute la fonction de manière synchrone.\n",
    "* Une fonction \n",
    "* Les arguments de la fonction \n",
    "\n",
    "Le prototype de cette fonction `std::async` est le suivant\n",
    "\n",
    "```c++\n",
    "template <class Fn, class... Args>\n",
    "future<typename result_of<Fn(Args...)>::type> async (launch policy, Fn&& fn, Args&&... args);\n",
    "```\n",
    "\n",
    "On voit alors que cette fonction `async` nous renvoie un objet de type `std::future<T>`. L'objet `std::future<T>` est templaté par le type de retour de la fonction `fn` que vous donnez à votre `std::async`. Le `std::future` permet une encapsulation du résultat de la fonction asynchrone, permettant ainsi de toujours avoir le résultat a porté de main dans le programme principale.\n",
    "\n",
    "Pour récupérer la valeur associée au `std::future` il suffit d'appeler la méthode `get()` qui vous renvoie alors la valeur retournée par votre fonction asynchrone. Si la fonction ne s'est pas encore exécutée ou n'est pas terminée au moment du `get()` l'appel à `get()` est bloquant et donc attends la fin de l'exécution de la fonction asynchrone. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Voyons tout de suite un exemple : \n",
    "\n",
    "```c++\n",
    "#include <iostream>\n",
    "#include <future>\n",
    "\n",
    "int main(){\n",
    "\n",
    "  std::future<int> val = std::async(std::launch::async, []()-> int {\n",
    "      std::cout\t<< \"Hello from future\" << std::endl;\n",
    "      return 1.;\n",
    "    });\n",
    "\n",
    "\n",
    "  std::cout << \"Hello World from main\" << std::endl;\n",
    "\n",
    "  int value = val.get();\n",
    "  std::cout << \"Value = \" << value << std::endl;\n",
    "  return 0;\n",
    "\n",
    "}\n",
    "```\n",
    "\n",
    "```bash \n",
    "$ g++ main.cpp -o main -lpthread\n",
    "$ ./main \n",
    "Hello World from main\n",
    "Hello from future\n",
    "Value = 1\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour voir de manière plus concrête l'intérêt de l'asynchrone regardons un exemple un peu plus parlant. Considérons un programme qui doit récupérer des informations dans des bases de données. Chaque requêtes à une base prends 5 secondes. Le code séquentiel classique pour simuler ce comportement est le suivant : \n",
    "\n",
    "```c++ \n",
    "#include <iostream>\n",
    "#include <string>\n",
    "#include <chrono>\n",
    "#include <thread>\n",
    "\n",
    "using namespace std::chrono;\n",
    "\n",
    "std::string request_db(std::string req){\n",
    "  std::this_thread::sleep_for(seconds(5));\n",
    "  return \"DB_\" + req;\n",
    "}\n",
    "\n",
    "\n",
    "int main(){\n",
    "  system_clock::time_point start = system_clock::now();\n",
    "\n",
    "  std::string data1 = request_db(\"req db1\");\n",
    "  std::string data2 = request_db(\"req db2\");\n",
    "\n",
    "  auto end = system_clock::now();\n",
    "\n",
    "  auto diff = duration_cast < std::chrono::seconds > (end - start).count();\n",
    "  std::cout << \"Total Time = \" << diff << \" Seconds\" << std::endl;\n",
    "\n",
    "  std::string data = data1 + \" :: \" + data2;\n",
    "  std::cout << \"Data = \" << data << std::endl;\n",
    "\n",
    "  return 0;\n",
    "}\n",
    "```\n",
    "\n",
    "L'exécution de ce code donne alors comme résultat : \n",
    "\n",
    "```\n",
    "Total Time = 10 Seconds\n",
    "Data = DB_req db1 :: DB_req db2\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si maintenant on modifie très légèrement le code à coup de `std::async` on peut obtenir le code suivant : \n",
    "\n",
    "```c++ \n",
    "#include <iostream>\n",
    "#include <string>\n",
    "#include <chrono>\n",
    "#include <thread>\n",
    "#include <future>\n",
    "\n",
    "using namespace std::chrono;\n",
    "\n",
    "std::string request_db(std::string req){\n",
    "  std::this_thread::sleep_for(seconds(5));\n",
    "  return \"DB_\" + req;\n",
    "}\n",
    "\n",
    "\n",
    "int main(){\n",
    "  system_clock::time_point start = system_clock::now();\n",
    "\n",
    "  std::future<std::string> data1 = std::async(std::launch::async, request_db, \"req db1\");\n",
    "  std::future<std::string> data2 = std::async(std::launch::async, request_db,\"req db2\");\n",
    "\n",
    "  std::string data = data1.get() + \" :: \" + data2.get();\n",
    "\n",
    "  auto end = system_clock::now();\n",
    "  auto diff = duration_cast < std::chrono::seconds > (end - start).count();\n",
    "  std::cout << \"Total Time = \" << diff << \" Seconds\" << std::endl;\n",
    "\n",
    "  std::cout << \"Data = \" << data << std::endl;\n",
    "\n",
    "  return 0;\n",
    "}\n",
    "```\n",
    "\n",
    "On obtient alors le résultat suivant : \n",
    "```\n",
    "Total Time = 5 Seconds\n",
    "Data = DB_req db1 :: DB_req db2\n",
    "```\n",
    "\n",
    "Donc comme prévu le temps d'exécution est réduit à 5 secondes car les tâches se font simultanément !!! Wouaaaahhh oui je sais c'est génial. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour finir ce premier tour d'horizon de la concurrence en C++ je vous propose de faire un exemple de gestin d'un ensemble de tâches. Il s'agit d'un système où l'on a une queue contenant les différents paramètres d'entrée, par exemple une requère à faire à une base de donnée, et des `workers` viennent piocher dans la queue font la requête et mettent le résultat dans une nouvelle `queue`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Si vous êtes encore bien eveillé vous aurez peut-être remarqué que dans le scénario précédent on a besoin d'une `queue` mais il faut qu'elle soit un peu particulière puisque qu'elle va être partagée entre plusieurs fil d'exécution... Il faut donc que l'on s'occupe des problèmes d'accès concurrents. En d'autre mot quand on va faire un `pop()` par exemple et bien il faut être sur qu'un autre fil d'exécution ne fait pas un `pop()` exactement au même moment. Il nous faut donc une `queue` qui soit *thread-safe*.  Alors dans les cours Python vous avez l'habitude que je vous dise qu'il s'agit d'un langage merveilleux et donc que tout est déjà fait pour vous ... Et bien pas de chance en C++ c'est pas la même chose, néanmoins C++ reste un langage merveilleux pas de doute à ce sujet. Mais on vous prend moins la main donc pas de `queue` thread-safe sur étagère. Mais pas d'inquiétude vous allez voir c'est facile. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Alors pour faire notre `queue` asynchrone, que l'on appelera avec beaucoup d'originalité `AsyncQueue` nous allons avoir besoin de trois choses : \n",
    "\n",
    "* La queue synchrone classique de la librairie standard `std::queue`\n",
    "* Un mutex qui nous permettra de vérouiller la queue lorsque l'on opère dessus\n",
    "* Une variable conditionnelle `std::condition_variable`, il s'agit d'un objet de la librairie standard qui permet de synchroniser les threads et de notifier des threads de certains évènements. \n",
    "\n",
    "Le fonctionnement attendu de la `AsyncQueue` est le suivant : lorsqu'un thread fait une action sur la queue (`push`, `pop` ou `empty`), un threads qui voudrait faire une action quelconque sur le queue est bloqué, un thread qui ne touche pas à la queue continu sont exécution. \n",
    " \n",
    "Ci-dessous un exemple d'implémentation de cette `AsyncQueue`, vous remarquerez l'usage de la méthode `wait` dans la méthode `pop` qui dans le cas où la queue est vide permet à un thread d'attendre qu'un autre thread fasse un `push` pour retourner un résultat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```c++\n",
    "#include <queue>\n",
    "#include <mutex>\n",
    "#include <condition_variable>\n",
    "\n",
    "\n",
    "template<typename T>\n",
    "class AsyncQueue{\n",
    "private:\n",
    "    std::queue<T> _queue;\n",
    "    std::mutex _mtx;\n",
    "    std::condition_variable _notifier;\n",
    "\n",
    "public:\n",
    "    AsyncQueue()=default;\n",
    "    AsyncQueue(const AsyncQueue&) = delete;\n",
    "    AsyncQueue& operator=(const AsyncQueue&) = delete;\n",
    "\n",
    "    bool empty(){\n",
    "        std::unique_lock<std::mutex> lock(this->_mutex);\n",
    "        bool ret = this->_queue.empty();\n",
    "        mlock.unlock();\n",
    "        return ret;\n",
    "    }\n",
    "\n",
    "    void push(const T& x){\n",
    "        std::unique_lock<std::mutex> lock(this->_mutex);\n",
    "        this->_queue.push(x);\n",
    "        mlock.unlock();\n",
    "        this->_notifier.notify_one();\n",
    "    }\n",
    "\n",
    "    T pop(){\n",
    "        std::unique_lock<std::mutex> lock(this->_mutex);\n",
    "        while(this->queue.empty()){\n",
    "            this->_notifier.wait(mlock);\n",
    "        }\n",
    "        T val = this->_queue.front(x);\n",
    "        this->_queue.pop();\n",
    "        return val;\n",
    "    }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Une fois que nous avons fait notre `AsyncQueue` nous avons fait le plus dur !! Le reste c'est facile. Alors juste pour le cosmétique nous allons commencer par faire une fonction `async_print` qui va s'assurer que l'on ait pas de chevauchement des lignes à l'affichage. \n",
    "\n",
    "```c++\n",
    "void async_print(std::string x) {     // Thread safe print \n",
    "  static std::mutex mutex;\n",
    "  std::unique_lock<std::mutex> locker(mutex);\n",
    "  std::cout << x << \"\\n\";\n",
    "  locker.unlock();\n",
    "}\n",
    "```\n",
    "\n",
    "Ensuite on fait notre fonction `worker` qui prend en entrée la queue contenant les données d'entrées et la queue initialement vide qui va nous permettre de stocker les résultats. Le principe de cette fonction est très simple, tant que la queue des entrées n'est pas vide on fait quelque chose. Le quelque chose en question dans ce cas étant de dormir pendant X secondes avec X le numéro du worker. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```c++\n",
    "void worker(AsyncQueue<int>& input, unsigned int id, AsyncQueue<std::string>& output) {\n",
    "  while( ! input.empty() ){\n",
    "    auto item = input.pop();\n",
    "    std::ostringstream tmp;\n",
    "    tmp << \" \" << item << \" --> C\" << id;\n",
    "    async_print(tmp.str());\n",
    "    std::this_thread::sleep_for(std::chrono::seconds(id));\n",
    "    tmp.str(\"\");\n",
    "    tmp << \"       \" << item << \" done \" << \"C\" << id << \" --->  results\";\n",
    "    async_print(tmp.str());\n",
    "    tmp.str(\"\");\n",
    "    tmp << \"done \" << item;\n",
    "    output.push( tmp.str() );\n",
    "  }\n",
    "}\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pour finir nous pouvons alors écrire notre `main` de la manière suivante par exemple."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```c++\n",
    "int main()\n",
    "{\n",
    "  const int nbWorker {4};\n",
    "  const int nbInput {14};\n",
    "\n",
    "  AsyncQueue<int> q;\n",
    "  AsyncQueue<std::string> results;\n",
    "\n",
    "  for( int i=0; i<nbInput ; i++){\n",
    "    q.push( i );\n",
    "  }\n",
    "\n",
    "  std::vector<std::future<void> > workers;\n",
    "  for (int i = 0 ; i < nbWorker ; ++i) {\n",
    "    std::future<void> w = std::async(std::launch::async, worker, std::ref(q), i + 1, std::ref(results));\n",
    "    workers.push_back(std::move(w));\n",
    "  }\n",
    "\n",
    "  for (auto& w : workers) {\n",
    "    c.get();\n",
    "  }\n",
    "\n",
    "  while(!results.empty()){\n",
    "    std::cout << results.pop() << std::endl;\n",
    "  }\n",
    "}\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L'exécution de ce code donne alors le résultat suivant : \n",
    "\n",
    "```\n",
    " 1 --> Worker2\n",
    " 0 --> Worker1\n",
    " 2 --> Worker3\n",
    " 3 --> Worker4\n",
    "       0 done Worker1 --->  results\n",
    " 4 --> Worker1\n",
    "       1 done Worker2 --->  results\n",
    " 5 --> Worker2\n",
    "       4 done Worker1 --->  results\n",
    " 6 --> Worker1\n",
    "       2 done Worker3 --->  results\n",
    " 7 --> Worker3\n",
    "       6 done Worker1 --->  results\n",
    " 8 --> Worker1\n",
    "       5 done Worker2 --->  results\n",
    " 9 --> Worker2\n",
    "       3 done Worker4 --->  results\n",
    " 10 --> Worker4\n",
    "       8 done Worker1 --->  results\n",
    " 11 --> Worker1\n",
    "       11 done Worker1 --->  results\n",
    " 12 --> Worker1\n",
    "       9 done Worker2 --->  results\n",
    " 13 --> Worker2\n",
    "       7 done Worker3 --->  results\n",
    "       12 done Worker1 --->  results\n",
    "       10 done Worker4 --->  results\n",
    "       13 done Worker2 --->  results\n",
    "done 0\n",
    "done 1\n",
    "done 4\n",
    "done 2\n",
    "done 6\n",
    "done 5\n",
    "done 3\n",
    "done 8\n",
    "done 11\n",
    "done 9\n",
    "done 7\n",
    "done 12\n",
    "done 10\n",
    "done 13\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}